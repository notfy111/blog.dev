---
title: "Interpretable CNN: Insect Classification"
date: 2021-11-14T15:51:01-05:00
draft: False
---
## Background
Convolutional Neural Network has made ground-breaking achivements in the Computer Domain. Nowadays, it has been widely on different deep learning tasks including object classification, search engines, and face recognition. However, given its complex architecture and high abstraction level, CNN models have remained relatively un-explainable and are bestowed the name of "black box model." 
Researchers have been trying to find frameworks and tools that can help debunk the myths of CNN and make it more interpretable. SHAP[!https://github.com/slundberg/shap] is one of the most robust and easy-to-use tools that visualize and make sense of the model prediction. In this analysis, we are going to use a Tensorflow CNN model on insect images to create a classification model that distinguishes beetles, cockroaches, and dragonflies. Then we are going to use SHAP to interprete the model and understand how does the model made predictions.
## Data

## Model
## SHAP Interpretation